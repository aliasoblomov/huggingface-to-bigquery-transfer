{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUqeVLqcnQdmK/K27isM7E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aliasoblomov/huggingface-to-bigquery-transfer/blob/main/tansfer_divar_data_from_huggingface_to_bigquery.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edMbM4ZtMeFs"
      },
      "outputs": [],
      "source": [
        "# CELL¬†1: Install Libraries\n",
        "\n",
        "!pip install datasets pandas google-cloud-bigquery pyarrow db-dtypes -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL¬†2: Authenticate to Google Cloud\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "print('‚úÖ Authenticated')\n"
      ],
      "metadata": {
        "id": "L46Um3ftOETP",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL¬†3: Download from HF & Load into BigQuery (with retries)\n",
        "\n",
        "# === CONFIGURATION: REPLACE THESE ===\n",
        "gcp_project_id = \"azw-ua\"      # ‚Üê your GCP project ID\n",
        "bq_dataset_id  = \"real_estate_data\"     # ‚Üê your existing BigQuery dataset\n",
        "bq_table_id    = \"divar_real_estate_ads\"   # ‚Üê name for the new table\n",
        "hf_dataset     = \"divaroffical/real_estate_ads\"\n",
        "hf_split       = \"train\"\n",
        "bq_location    = \"US\"                      # ‚Üê match your dataset location\n",
        "# ===================================\n",
        "\n",
        "import time\n",
        "import pandas as pd\n",
        "from datasets import load_dataset\n",
        "from google.cloud import bigquery\n",
        "\n",
        "# Full table reference\n",
        "table_ref = f\"{gcp_project_id}.{bq_dataset_id}.{bq_table_id}\"\n",
        "\n",
        "print(f\"‚Üí HF dataset: {hf_dataset} [{hf_split}]\")\n",
        "print(f\"‚Üí BQ table:   {table_ref}  (location={bq_location})\\n\")\n",
        "\n",
        "# 1) Download HF dataset\n",
        "print(\"1) Downloading Hugging Face dataset‚Ä¶\")\n",
        "hf_ds = load_dataset(hf_dataset, split=hf_split)\n",
        "df    = hf_ds.to_pandas()\n",
        "print(f\"   ‚Üí Downloaded & converted to DataFrame: {df.shape[0]} rows, {df.shape[1]} cols\\n\")\n",
        "\n",
        "# 2) Initialize BQ client\n",
        "client = bigquery.Client(project=gcp_project_id, location=bq_location)\n",
        "job_config = bigquery.LoadJobConfig(\n",
        "    write_disposition=\"WRITE_TRUNCATE\",\n",
        "    autodetect=True,\n",
        ")\n",
        "\n",
        "# 3) Upload with retries\n",
        "max_retries = 5\n",
        "for attempt in range(1, max_retries+1):\n",
        "    try:\n",
        "        print(f\"{attempt=}: Starting load_job‚Ä¶\")\n",
        "        job = client.load_table_from_dataframe(df, table_ref, job_config=job_config)\n",
        "        job.result()  # wait for completion\n",
        "        print(f\"‚úÖ Loaded {job.output_rows} rows into {table_ref}\")\n",
        "        break\n",
        "    except Exception as err:\n",
        "        print(f\"‚ùå Attempt {attempt} failed: {err}\")\n",
        "        if attempt == max_retries:\n",
        "            raise RuntimeError(\"All retries failed‚Äîaborting.\") from err\n",
        "        backoff = 2 ** attempt\n",
        "        print(f\"   ‚Ü≥ retrying in {backoff}s‚Ä¶\")\n",
        "        time.sleep(backoff)\n",
        "\n",
        "print(\"\\nüéâ All done!\")\n"
      ],
      "metadata": {
        "id": "3UXzjvGlOJ74"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}